{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö¶ Traffic Clearance Predictor - Complete ML System\n",
    "\n",
    "This notebook implements a comprehensive machine learning system to predict traffic clearance times based on various factors including weather, vehicle count, time patterns, and environmental conditions.\n",
    "\n",
    "## üìã Project Overview\n",
    "- **Objective**: Predict traffic congestion clearance duration in minutes\n",
    "- **Algorithm**: Optimized Random Forest Regressor with hyperparameter tuning\n",
    "- **Features**: 8 engineered features including temporal and environmental variables\n",
    "- **Performance Goal**: Achieve 85%+ accuracy (R¬≤ score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìÖ Analysis started at: 2025-09-13 13:45:28\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: IMPORTS AND SETUP ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ DATASET OVERVIEW:\n",
      "üìä Shape: 168 rows √ó 12 columns\n",
      "üìã Columns: ['date', 'time', 'hour', 'day_of_week', 'day_name', 'vehicle_count', 'congestion_level', 'congestion_duration_minutes', 'is_weekend', 'weather', 'temperature', 'visibility']\n",
      "üéØ Target Variable: congestion_duration_minutes (5-96 minutes)\n",
      "‚úÖ No missing values found!\n",
      "\n",
      "üìà TRAFFIC PATTERNS:\n",
      "Average Congestion Duration: 27.8 minutes\n",
      "Average Vehicle Count: 33.5 vehicles\n",
      "Weather Conditions: ['Clear' 'Fog' 'Light Rain' 'Heavy Rain']\n",
      "Congestion Levels: ['Low' 'Medium' 'High']\n"
     ]
    }
   ],
   "source": [
    "# === STEP 2: DATA LOADING AND INITIAL EXPLORATION ===\n",
    "try:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(\"synthetic_traffic_data.csv\")\n",
    "    \n",
    "    print(\"üéØ DATASET OVERVIEW:\")\n",
    "    print(f\"üìä Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üìã Columns: {list(df.columns)}\")\n",
    "    print(f\"üéØ Target Variable: congestion_duration_minutes ({df['congestion_duration_minutes'].min()}-{df['congestion_duration_minutes'].max()} minutes)\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() == 0:\n",
    "        print(\"‚úÖ No missing values found!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing values detected:\\n{missing_values[missing_values > 0]}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìà TRAFFIC PATTERNS:\")\n",
    "    print(f\"Average Congestion Duration: {df['congestion_duration_minutes'].mean():.1f} minutes\")\n",
    "    print(f\"Average Vehicle Count: {df['vehicle_count'].mean():.1f} vehicles\")\n",
    "    print(f\"Weather Conditions: {df['weather'].unique()}\")\n",
    "    print(f\"Congestion Levels: {df['congestion_level'].unique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {str(e)}\")\n",
    "    print(\"Please ensure 'synthetic_traffic_data.csv' is in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FEATURE ENGINEERING IN PROGRESS...\n",
      "‚úÖ Feature engineering completed!\n",
      "üìä Basic features: 8\n",
      "üöÄ Engineered features: 17\n",
      "üéØ Target variable: congestion_duration_minutes\n",
      "\n",
      "üìã PROCESSED DATA SAMPLE:\n",
      "   hour  vehicle_count     weather  weather_encoded  is_rush_hour  \\\n",
      "0     0              7       Clear                0             0   \n",
      "1     1              2         Fog                1             0   \n",
      "2     2              0  Light Rain                3             0   \n",
      "3     3              0       Clear                0             0   \n",
      "4     4              0       Clear                0             0   \n",
      "\n",
      "   congestion_duration_minutes  \n",
      "0                            9  \n",
      "1                           10  \n",
      "2                            7  \n",
      "3                            8  \n",
      "4                           11  \n"
     ]
    }
   ],
   "source": [
    "# === STEP 3: DATA PREPROCESSING AND FEATURE ENGINEERING ===\n",
    "\n",
    "# Create a copy for processing\n",
    "data = df.copy()\n",
    "\n",
    "print(\"üîß FEATURE ENGINEERING IN PROGRESS...\")\n",
    "\n",
    "# 1. Encode categorical variables\n",
    "le_weather = LabelEncoder()\n",
    "le_congestion = LabelEncoder()\n",
    "\n",
    "data['weather_encoded'] = le_weather.fit_transform(data['weather'])\n",
    "data['congestion_level_encoded'] = le_congestion.fit_transform(data['congestion_level'])\n",
    "\n",
    "# Store encoders for future use\n",
    "encoders = {\n",
    "    'weather': le_weather,\n",
    "    'congestion_level': le_congestion\n",
    "}\n",
    "\n",
    "# 2. Create cyclical features for time\n",
    "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "data['day_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "data['day_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "\n",
    "# 3. Create rush hour indicator\n",
    "data['is_rush_hour'] = ((data['hour'] >= 7) & (data['hour'] <= 9) | \n",
    "                       (data['hour'] >= 17) & (data['hour'] <= 19)).astype(int)\n",
    "\n",
    "# 4. Weather severity mapping\n",
    "weather_severity = {'Clear': 1, 'Fog': 2, 'Light Rain': 3, 'Heavy Rain': 4}\n",
    "data['weather_severity'] = data['weather'].map(weather_severity)\n",
    "\n",
    "# 5. Vehicle density categories\n",
    "data['vehicle_density'] = pd.cut(data['vehicle_count'], \n",
    "                               bins=[0, 20, 50, 100], \n",
    "                               labels=['Low', 'Medium', 'High'],\n",
    "                               include_lowest=True)\n",
    "data['vehicle_density_encoded'] = LabelEncoder().fit_transform(data['vehicle_density'].astype(str))\n",
    "\n",
    "# 6. Interaction features\n",
    "data['weather_vehicle_interaction'] = data['weather_severity'] * data['vehicle_count'] / 100\n",
    "data['rush_weather_interaction'] = data['is_rush_hour'] * data['weather_severity']\n",
    "\n",
    "# Define feature sets\n",
    "basic_features = [\n",
    "    'hour', 'day_of_week', 'vehicle_count', 'is_weekend',\n",
    "    'temperature', 'visibility', 'weather_encoded', 'congestion_level_encoded'\n",
    "]\n",
    "\n",
    "engineered_features = basic_features + [\n",
    "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "    'is_rush_hour', 'weather_severity', 'vehicle_density_encoded',\n",
    "    'weather_vehicle_interaction', 'rush_weather_interaction'\n",
    "]\n",
    "\n",
    "target_variable = 'congestion_duration_minutes'\n",
    "\n",
    "print(f\"‚úÖ Feature engineering completed!\")\n",
    "print(f\"üìä Basic features: {len(basic_features)}\")\n",
    "print(f\"üöÄ Engineered features: {len(engineered_features)}\")\n",
    "print(f\"üéØ Target variable: {target_variable}\")\n",
    "\n",
    "# Display sample of processed data\n",
    "print(f\"\\nüìã PROCESSED DATA SAMPLE:\")\n",
    "display_cols = ['hour', 'vehicle_count', 'weather', 'weather_encoded', 'is_rush_hour', 'congestion_duration_minutes']\n",
    "print(data[display_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà TRAFFIC PATTERN ANALYSIS:\n",
      "\n",
      "üö¶ RUSH HOUR IMPACT:\n",
      "             congestion_duration_minutes        vehicle_count\n",
      "                                    mean    std          mean\n",
      "is_rush_hour                                                 \n",
      "0                                  21.18  15.16         24.82\n",
      "1                                  47.55  22.89         59.64\n",
      "\n",
      "üåßÔ∏è WEATHER IMPACT:\n",
      "           congestion_duration_minutes       vehicle_count\n",
      "                                  mean count          mean\n",
      "weather                                                   \n",
      "Clear                            25.24    51         30.69\n",
      "Fog                              26.41    34         32.97\n",
      "Heavy Rain                       34.61    38         39.55\n",
      "Light Rain                       25.91    45         32.07\n",
      "\n",
      "‚è∞ PEAK TRAFFIC HOURS:\n",
      "      congestion_duration_minutes  vehicle_count\n",
      "hour                                            \n",
      "17                          56.57          74.86\n",
      "18                          58.14          73.71\n",
      "8                           59.29          69.71\n",
      "16                          42.29          63.14\n",
      "13                          32.71          51.71\n",
      "\n",
      "üîó TOP CORRELATIONS WITH TARGET:\n",
      "vehicle_count       0.839196\n",
      "is_rush_hour        0.551008\n",
      "hour                0.229095\n",
      "weather_severity    0.142180\n",
      "temperature        -0.057944\n",
      "visibility          0.020219\n",
      "Name: congestion_duration_minutes, dtype: float64\n",
      "\n",
      "üìÖ WEEKEND vs WEEKDAY PATTERNS:\n",
      "           congestion_duration_minutes        vehicle_count    \n",
      "                                  mean    std          mean max\n",
      "is_weekend                                                     \n",
      "0                                31.30  21.81         38.02  96\n",
      "1                                18.96  14.80         22.29  56\n"
     ]
    }
   ],
   "source": [
    "# === STEP 4: EXPLORATORY DATA ANALYSIS ===\n",
    "\n",
    "print(\"üìà TRAFFIC PATTERN ANALYSIS:\")\n",
    "\n",
    "# 1. Rush hour analysis\n",
    "rush_hour_stats = data.groupby('is_rush_hour').agg({\n",
    "    'congestion_duration_minutes': ['mean', 'std'],\n",
    "    'vehicle_count': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nüö¶ RUSH HOUR IMPACT:\")\n",
    "print(rush_hour_stats)\n",
    "\n",
    "# 2. Weather impact analysis\n",
    "weather_impact = data.groupby('weather').agg({\n",
    "    'congestion_duration_minutes': ['mean', 'count'],\n",
    "    'vehicle_count': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nüåßÔ∏è WEATHER IMPACT:\")\n",
    "print(weather_impact)\n",
    "\n",
    "# 3. Hourly patterns\n",
    "hourly_patterns = data.groupby('hour').agg({\n",
    "    'congestion_duration_minutes': 'mean',\n",
    "    'vehicle_count': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\n‚è∞ PEAK TRAFFIC HOURS:\")\n",
    "peak_hours = hourly_patterns.nlargest(5, 'vehicle_count')\n",
    "print(peak_hours)\n",
    "\n",
    "# 4. Correlation analysis\n",
    "correlation_features = ['hour', 'vehicle_count', 'temperature', 'visibility', \n",
    "                       'weather_severity', 'is_rush_hour', 'congestion_duration_minutes']\n",
    "correlation_matrix = data[correlation_features].corr()\n",
    "\n",
    "print(f\"\\nüîó TOP CORRELATIONS WITH TARGET:\")\n",
    "target_corr = correlation_matrix['congestion_duration_minutes'].sort_values(key=abs, ascending=False)\n",
    "print(target_corr.drop('congestion_duration_minutes').head(6))\n",
    "\n",
    "# 5. Weekend vs Weekday analysis\n",
    "weekend_analysis = data.groupby('is_weekend').agg({\n",
    "    'congestion_duration_minutes': ['mean', 'std'],\n",
    "    'vehicle_count': ['mean', 'max']\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nüìÖ WEEKEND vs WEEKDAY PATTERNS:\")\n",
    "print(weekend_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AdvancedTrafficPredictor class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# === STEP 5: ADVANCED ML MODEL WITH HYPERPARAMETER OPTIMIZATION ===\n",
    "\n",
    "class AdvancedTrafficPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.feature_names = None\n",
    "        self.performance_metrics = {}\n",
    "        self.feature_importance = None\n",
    "        self.is_trained = False\n",
    "        self.encoders = None\n",
    "    \n",
    "    def prepare_data(self, data, feature_columns, target_column, test_size=0.2):\n",
    "        \"\"\"Prepare and split data for training\"\"\"\n",
    "        try:\n",
    "            # Extract features and target\n",
    "            X = data[feature_columns].copy()\n",
    "            y = data[target_column].copy()\n",
    "            \n",
    "            # Handle any remaining missing values\n",
    "            X = X.fillna(X.mean())\n",
    "            \n",
    "            # Store feature names\n",
    "            self.feature_names = feature_columns\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=42, stratify=None\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            self.scaler = StandardScaler()\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            return X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Data preparation error: {str(e)}\")\n",
    "            return None, None, None, None, None, None\n",
    "    \n",
    "    def optimize_hyperparameters(self, X_train, y_train):\n",
    "        \"\"\"Perform hyperparameter optimization\"\"\"\n",
    "        print(\"üîÑ Hyperparameter optimization in progress...\")\n",
    "        \n",
    "        # Define parameter distributions\n",
    "        param_distributions = {\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [10, 15, 20, 25, 30, None],\n",
    "            'min_samples_split': [2, 3, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4, 6],\n",
    "            'max_features': ['sqrt', 'log2', None],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "        \n",
    "        # Create base model\n",
    "        base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "        \n",
    "        # Randomized search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=50,\n",
    "            cv=5,\n",
    "            scoring='r2',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"‚úÖ Best CV Score: {random_search.best_score_:.4f}\")\n",
    "        print(f\"üéØ Best Parameters: {random_search.best_params_}\")\n",
    "        \n",
    "        return random_search.best_estimator_\n",
    "    \n",
    "    def train_model(self, data, feature_columns, target_column):\n",
    "        \"\"\"Train the complete model\"\"\"\n",
    "        try:\n",
    "            print(\"üöÄ TRAINING ADVANCED TRAFFIC PREDICTOR\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Prepare data\n",
    "            X_train_scaled, X_test_scaled, y_train, y_test, X_train_orig, X_test_orig = \\\n",
    "                self.prepare_data(data, feature_columns, target_column)\n",
    "            \n",
    "            if X_train_scaled is None:\n",
    "                return False\n",
    "            \n",
    "            print(f\"üìä Training samples: {X_train_scaled.shape[0]}\")\n",
    "            print(f\"üìä Test samples: {X_test_scaled.shape[0]}\")\n",
    "            print(f\"üìä Features: {X_train_scaled.shape[1]}\")\n",
    "            \n",
    "            # Optimize hyperparameters\n",
    "            self.model = self.optimize_hyperparameters(X_train_scaled, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred_train = self.model.predict(X_train_scaled)\n",
    "            y_pred_test = self.model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_r2 = r2_score(y_train, y_pred_train)\n",
    "            test_r2 = r2_score(y_test, y_pred_test)\n",
    "            test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "            \n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "            \n",
    "            # Store metrics\n",
    "            self.performance_metrics = {\n",
    "                'train_r2': train_r2,\n",
    "                'test_r2': test_r2,\n",
    "                'test_mae': test_mae,\n",
    "                'test_rmse': test_rmse,\n",
    "                'cv_mean': cv_scores.mean(),\n",
    "                'cv_std': cv_scores.std(),\n",
    "                'accuracy_percentage': test_r2 * 100\n",
    "            }\n",
    "            \n",
    "            # Feature importance\n",
    "            self.feature_importance = self.model.feature_importances_\n",
    "            \n",
    "            # Model is trained\n",
    "            self.is_trained = True\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\nüèÜ TRAINING RESULTS:\")\n",
    "            print(f\"‚úÖ Training R¬≤: {train_r2:.4f}\")\n",
    "            print(f\"‚úÖ Test R¬≤: {test_r2:.4f} ({test_r2*100:.2f}% accuracy)\")\n",
    "            print(f\"‚úÖ Test MAE: {test_mae:.2f} minutes\")\n",
    "            print(f\"‚úÖ Test RMSE: {test_rmse:.2f} minutes\")\n",
    "            print(f\"‚úÖ CV Score: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training error: {str(e)}\")\n",
    "            self.is_trained = False\n",
    "            return False\n",
    "    \n",
    "    def get_feature_importance(self, top_n=10):\n",
    "        \"\"\"Get feature importance analysis\"\"\"\n",
    "        if not self.is_trained or self.feature_importance is None:\n",
    "            return None\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': self.feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df.head(top_n)\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        \n",
    "        # Ensure input has correct features\n",
    "        input_scaled = self.scaler.transform(input_data[self.feature_names])\n",
    "        return self.model.predict(input_scaled)\n",
    "    \n",
    "    def save_model(self, filepath=\"traffic_predictor_model.pkl\"):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        if self.is_trained:\n",
    "            model_data = {\n",
    "                'model': self.model,\n",
    "                'scaler': self.scaler,\n",
    "                'feature_names': self.feature_names,\n",
    "                'performance_metrics': self.performance_metrics,\n",
    "                'encoders': self.encoders\n",
    "            }\n",
    "            joblib.dump(model_data, filepath)\n",
    "            print(f\"‚úÖ Model saved as {filepath}\")\n",
    "        else:\n",
    "            print(\"‚ùå No trained model to save!\")\n",
    "\n",
    "print(\"‚úÖ AdvancedTrafficPredictor class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ COMPARING MODEL CONFIGURATIONS:\n",
      "============================================================\n",
      "\n",
      "üîµ MODEL 1: Basic Features\n",
      "üöÄ TRAINING ADVANCED TRAFFIC PREDICTOR\n",
      "==================================================\n",
      "üìä Training samples: 134\n",
      "üìä Test samples: 34\n",
      "üìä Features: 8\n",
      "üîÑ Hyperparameter optimization in progress...\n",
      "‚úÖ Best CV Score: 0.6849\n",
      "üéØ Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 25, 'bootstrap': True}\n",
      "\n",
      "üèÜ TRAINING RESULTS:\n",
      "‚úÖ Training R¬≤: 0.8109\n",
      "‚úÖ Test R¬≤: 0.8622 (86.22% accuracy)\n",
      "‚úÖ Test MAE: 6.34 minutes\n",
      "‚úÖ Test RMSE: 8.17 minutes\n",
      "‚úÖ CV Score: 0.6849 ¬± 0.0627\n",
      "\n",
      "üü¢ MODEL 2: Engineered Features\n",
      "üöÄ TRAINING ADVANCED TRAFFIC PREDICTOR\n",
      "==================================================\n",
      "üìä Training samples: 134\n",
      "üìä Test samples: 34\n",
      "üìä Features: 17\n",
      "üîÑ Hyperparameter optimization in progress...\n",
      "‚úÖ Best CV Score: 0.6994\n",
      "üéØ Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': True}\n",
      "\n",
      "üèÜ TRAINING RESULTS:\n",
      "‚úÖ Training R¬≤: 0.7947\n",
      "‚úÖ Test R¬≤: 0.8385 (83.85% accuracy)\n",
      "‚úÖ Test MAE: 6.67 minutes\n",
      "‚úÖ Test RMSE: 8.85 minutes\n",
      "‚úÖ CV Score: 0.6994 ¬± 0.0820\n",
      "\n",
      "üìä PERFORMANCE COMPARISON:\n",
      "============================================================\n",
      "               Basic Features Engineered Features\n",
      "R¬≤ Score               0.8622              0.8385\n",
      "MAE (minutes)            6.34                6.67\n",
      "RMSE (minutes)           8.17                8.85\n",
      "Accuracy               86.22%              83.85%\n",
      "\n",
      "üèÜ WINNER: Basic Features\n",
      "\n",
      "üéØ TOP 10 MOST IMPORTANT FEATURES:\n",
      "============================================================\n",
      " 3. vehicle_count             0.4570\n",
      " 8. congestion_level_encoded  0.3372\n",
      " 1. hour                      0.1143\n",
      " 5. temperature               0.0370\n",
      " 2. day_of_week               0.0259\n",
      " 7. weather_encoded           0.0138\n",
      " 4. is_weekend                0.0095\n",
      " 6. visibility                0.0053\n",
      "\n",
      "üé™ FINAL MODEL PERFORMANCE ANALYSIS:\n",
      "============================================================\n",
      "‚≠ê VERY GOOD: Strong predictive performance achieved!\n",
      "   Suitable for real-world applications.\n"
     ]
    }
   ],
   "source": [
    "# === STEP 6: TRAIN AND EVALUATE MODELS ===\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = AdvancedTrafficPredictor()\n",
    "predictor.encoders = encoders\n",
    "\n",
    "print(\"üéØ COMPARING MODEL CONFIGURATIONS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train with basic features\n",
    "print(\"\\nüîµ MODEL 1: Basic Features\")\n",
    "basic_success = predictor.train_model(data, basic_features, target_variable)\n",
    "basic_performance = predictor.performance_metrics.copy() if basic_success else {}\n",
    "\n",
    "# Train with engineered features\n",
    "print(\"\\nüü¢ MODEL 2: Engineered Features\")\n",
    "predictor_advanced = AdvancedTrafficPredictor()\n",
    "predictor_advanced.encoders = encoders\n",
    "advanced_success = predictor_advanced.train_model(data, engineered_features, target_variable)\n",
    "advanced_performance = predictor_advanced.performance_metrics.copy() if advanced_success else {}\n",
    "\n",
    "# Compare results\n",
    "if basic_success and advanced_success:\n",
    "    print(\"\\nüìä PERFORMANCE COMPARISON:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Basic Features': [\n",
    "            f\"{basic_performance['test_r2']:.4f}\",\n",
    "            f\"{basic_performance['test_mae']:.2f}\",\n",
    "            f\"{basic_performance['test_rmse']:.2f}\",\n",
    "            f\"{basic_performance['accuracy_percentage']:.2f}%\"\n",
    "        ],\n",
    "        'Engineered Features': [\n",
    "            f\"{advanced_performance['test_r2']:.4f}\",\n",
    "            f\"{advanced_performance['test_mae']:.2f}\",\n",
    "            f\"{advanced_performance['test_rmse']:.2f}\",\n",
    "            f\"{advanced_performance['accuracy_percentage']:.2f}%\"\n",
    "        ]\n",
    "    }, index=['R¬≤ Score', 'MAE (minutes)', 'RMSE (minutes)', 'Accuracy'])\n",
    "    \n",
    "    print(comparison)\n",
    "    \n",
    "    # Determine best model\n",
    "    if advanced_performance['test_r2'] > basic_performance['test_r2']:\n",
    "        best_model = predictor_advanced\n",
    "        model_name = \"Advanced (Engineered Features)\"\n",
    "        improvement = (advanced_performance['test_r2'] - basic_performance['test_r2']) * 100\n",
    "        print(f\"\\nüèÜ WINNER: {model_name}\")\n",
    "        print(f\"üìà Improvement: +{improvement:.2f}% accuracy\")\n",
    "    else:\n",
    "        best_model = predictor\n",
    "        model_name = \"Basic Features\"\n",
    "        print(f\"\\nüèÜ WINNER: {model_name}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Model training failed!\")\n",
    "    best_model = None\n",
    "\n",
    "# Feature importance analysis\n",
    "if best_model and best_model.is_trained:\n",
    "    print(f\"\\nüéØ TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "    print(\"=\"*60)\n",
    "    feature_imp = best_model.get_feature_importance(top_n=10)\n",
    "    \n",
    "    for idx, row in feature_imp.iterrows():\n",
    "        print(f\"{idx+1:2d}. {row['feature']:25s} {row['importance']:.4f}\")\n",
    "    \n",
    "    # Performance interpretation\n",
    "    final_accuracy = best_model.performance_metrics['accuracy_percentage']\n",
    "    print(f\"\\nüé™ FINAL MODEL PERFORMANCE ANALYSIS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if final_accuracy >= 90:\n",
    "        print(\"üåü OUTSTANDING: Excellent performance for traffic prediction!\")\n",
    "        print(\"   Ready for production deployment.\")\n",
    "    elif final_accuracy >= 85:\n",
    "        print(\"‚≠ê VERY GOOD: Strong predictive performance achieved!\")\n",
    "        print(\"   Suitable for real-world applications.\")\n",
    "    elif final_accuracy >= 75:\n",
    "        print(\"üëç GOOD: Solid performance with room for improvement.\")\n",
    "        print(\"   Consider additional feature engineering.\")\n",
    "    else:\n",
    "        print(\"üîÑ NEEDS IMPROVEMENT: Model requires optimization.\")\n",
    "        print(\"   Consider more data or different algorithms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING MODEL WITH SAMPLE SCENARIOS:\n",
      "============================================================\n",
      "üåÖ Rush Hour - Clear Weather\n",
      "   üïí Predicted Clearance Time: 43.3 minutes\n",
      "   üö® Significant delay expected\n",
      "\n",
      "üåßÔ∏è Heavy Rain - Peak Traffic\n",
      "   üïí Predicted Clearance Time: 43.3 minutes\n",
      "   üö® Significant delay expected\n",
      "\n",
      "üòé Weekend - Light Traffic\n",
      "   üïí Predicted Clearance Time: 18.5 minutes\n",
      "   ‚ö†Ô∏è  Moderate delay expected\n",
      "\n",
      "üåô Late Night - Minimal Traffic\n",
      "   üïí Predicted Clearance Time: 26.6 minutes\n",
      "   ‚ö†Ô∏è  Moderate delay expected\n",
      "\n",
      "üå´Ô∏è Foggy Morning Commute\n",
      "   üïí Predicted Clearance Time: 41.1 minutes\n",
      "   üö® Significant delay expected\n",
      "\n",
      "üíæ SAVING MODEL:\n",
      "==============================\n",
      "‚úÖ Model saved as advanced_traffic_predictor.pkl\n",
      "\n",
      "üéä MODEL TRAINING COMPLETED SUCCESSFULLY!\n",
      "üìà Final Model Accuracy: 86.22%\n",
      "üéØ Model Type: Basic Features\n",
      "üíæ Model Saved As: advanced_traffic_predictor.pkl\n",
      "\n",
      "üöÄ Your Traffic Clearance Predictor is ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# === STEP 7: MODEL TESTING WITH SAMPLE PREDICTIONS ===\n",
    "\n",
    "if best_model and best_model.is_trained:\n",
    "    print(\"üß™ TESTING MODEL WITH SAMPLE SCENARIOS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create test scenarios\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            'name': 'üåÖ Rush Hour - Clear Weather',\n",
    "            'hour': 8, 'day_of_week': 1, 'vehicle_count': 85, 'is_weekend': 0,\n",
    "            'temperature': 25, 'visibility': 10, 'weather_encoded': 0, 'congestion_level_encoded': 2\n",
    "        },\n",
    "        {\n",
    "            'name': 'üåßÔ∏è Heavy Rain - Peak Traffic',\n",
    "            'hour': 17, 'day_of_week': 2, 'vehicle_count': 95, 'is_weekend': 0,\n",
    "            'temperature': 20, 'visibility': 7, 'weather_encoded': 2, 'congestion_level_encoded': 2\n",
    "        },\n",
    "        {\n",
    "            'name': 'üòé Weekend - Light Traffic',\n",
    "            'hour': 14, 'day_of_week': 6, 'vehicle_count': 30, 'is_weekend': 1,\n",
    "            'temperature': 28, 'visibility': 10, 'weather_encoded': 0, 'congestion_level_encoded': 1\n",
    "        },\n",
    "        {\n",
    "            'name': 'üåô Late Night - Minimal Traffic',\n",
    "            'hour': 2, 'day_of_week': 3, 'vehicle_count': 5, 'is_weekend': 0,\n",
    "            'temperature': 18, 'visibility': 10, 'weather_encoded': 0, 'congestion_level_encoded': 0\n",
    "        },\n",
    "        {\n",
    "            'name': 'üå´Ô∏è Foggy Morning Commute',\n",
    "            'hour': 7, 'day_of_week': 4, 'vehicle_count': 70, 'is_weekend': 0,\n",
    "            'temperature': 22, 'visibility': 8, 'weather_encoded': 1, 'congestion_level_encoded': 2\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Make predictions for each scenario\n",
    "    for scenario in test_scenarios:\n",
    "        scenario_name = scenario.pop('name')\n",
    "        \n",
    "        # Create DataFrame for prediction\n",
    "        scenario_df = pd.DataFrame([scenario])\n",
    "        \n",
    "        # Add engineered features if using advanced model\n",
    "        if len(best_model.feature_names) > len(basic_features):\n",
    "            # Add cyclical features\n",
    "            scenario_df['hour_sin'] = np.sin(2 * np.pi * scenario_df['hour'] / 24)\n",
    "            scenario_df['hour_cos'] = np.cos(2 * np.pi * scenario_df['hour'] / 24)\n",
    "            scenario_df['day_sin'] = np.sin(2 * np.pi * scenario_df['day_of_week'] / 7)\n",
    "            scenario_df['day_cos'] = np.cos(2 * np.pi * scenario_df['day_of_week'] / 7)\n",
    "            \n",
    "            # Add other engineered features\n",
    "            scenario_df['is_rush_hour'] = ((scenario_df['hour'] >= 7) & (scenario_df['hour'] <= 9) | \n",
    "                                         (scenario_df['hour'] >= 17) & (scenario_df['hour'] <= 19)).astype(int)\n",
    "            \n",
    "            # Map weather severity\n",
    "            weather_map = {0: 1, 1: 2, 2: 4, 3: 3}  # Clear, Fog, Heavy Rain, Light Rain\n",
    "            scenario_df['weather_severity'] = scenario_df['weather_encoded'].map(weather_map)\n",
    "            \n",
    "            # Vehicle density\n",
    "            vehicle_count = scenario_df['vehicle_count'].iloc[0]\n",
    "            if vehicle_count <= 20:\n",
    "                scenario_df['vehicle_density_encoded'] = 0\n",
    "            elif vehicle_count <= 50:\n",
    "                scenario_df['vehicle_density_encoded'] = 1\n",
    "            else:\n",
    "                scenario_df['vehicle_density_encoded'] = 2\n",
    "            \n",
    "            # Interaction features\n",
    "            scenario_df['weather_vehicle_interaction'] = scenario_df['weather_severity'] * scenario_df['vehicle_count'] / 100\n",
    "            scenario_df['rush_weather_interaction'] = scenario_df['is_rush_hour'] * scenario_df['weather_severity']\n",
    "        \n",
    "        try:\n",
    "            prediction = best_model.predict(scenario_df)[0]\n",
    "            print(f\"{scenario_name}\")\n",
    "            print(f\"   üïí Predicted Clearance Time: {prediction:.1f} minutes\")\n",
    "            \n",
    "            # Add context\n",
    "            if prediction < 15:\n",
    "                print(f\"   ‚úÖ Quick clearance expected\")\n",
    "            elif prediction < 30:\n",
    "                print(f\"   ‚ö†Ô∏è  Moderate delay expected\")\n",
    "            elif prediction < 60:\n",
    "                print(f\"   üö® Significant delay expected\")\n",
    "            else:\n",
    "                print(f\"   üî¥ Major traffic disruption expected\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Prediction error: {str(e)}\")\n",
    "            print()\n",
    "    \n",
    "    # Save the model\n",
    "    print(\"üíæ SAVING MODEL:\")\n",
    "    print(\"=\"*30)\n",
    "    best_model.save_model(\"advanced_traffic_predictor.pkl\")\n",
    "    \n",
    "    print(f\"\\nüéä MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"üìà Final Model Accuracy: {best_model.performance_metrics['accuracy_percentage']:.2f}%\")\n",
    "    print(f\"üéØ Model Type: {model_name}\")\n",
    "    print(f\"üíæ Model Saved As: advanced_traffic_predictor.pkl\")\n",
    "    print(f\"\\nüöÄ Your Traffic Clearance Predictor is ready for deployment!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No trained model available for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã FINAL MODEL SUMMARY:\n",
      "============================================================\n",
      "üéØ Model Type              Random Forest Regressor (Optimized)\n",
      "üìä Dataset Size            168 records\n",
      "üîß Features Used           8 features\n",
      "üìà Accuracy (R¬≤)           86.22%\n",
      "üìâ Mean Absolute Error     6.34 minutes\n",
      "üìê Root Mean Square Error  8.17 minutes\n",
      "üîÑ Cross-Validation        0.6849 ¬± 0.0627\n",
      "üíæ Model File              advanced_traffic_predictor.pkl\n",
      "\n",
      "üöÄ DEPLOYMENT INSTRUCTIONS:\n",
      "============================================================\n",
      "üìù Sample deployment code saved in model summary.\n",
      "\n",
      "‚úÖ Traffic Clearance Predictor is fully operational!\n",
      "üéâ Ready for real-time traffic management applications!\n",
      "\n",
      "üíæ Deployment example saved as 'deployment_example.py'\n",
      "\n",
      "============================================================\n",
      "üéä TRAFFIC CLEARANCE PREDICTOR PROJECT COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# === STEP 8: MODEL SUMMARY AND DEPLOYMENT INSTRUCTIONS ===\n",
    "\n",
    "if best_model and best_model.is_trained:\n",
    "    print(\"üìã FINAL MODEL SUMMARY:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    metrics = best_model.performance_metrics\n",
    "    \n",
    "    summary_info = {\n",
    "        'üéØ Model Type': 'Random Forest Regressor (Optimized)',\n",
    "        'üìä Dataset Size': f\"{data.shape[0]} records\",\n",
    "        'üîß Features Used': f\"{len(best_model.feature_names)} features\",\n",
    "        'üìà Accuracy (R¬≤)': f\"{metrics['accuracy_percentage']:.2f}%\",\n",
    "        'üìâ Mean Absolute Error': f\"{metrics['test_mae']:.2f} minutes\",\n",
    "        'üìê Root Mean Square Error': f\"{metrics['test_rmse']:.2f} minutes\",\n",
    "        'üîÑ Cross-Validation': f\"{metrics['cv_mean']:.4f} ¬± {metrics['cv_std']:.4f}\",\n",
    "        'üíæ Model File': 'advanced_traffic_predictor.pkl'\n",
    "    }\n",
    "    \n",
    "    for key, value in summary_info.items():\n",
    "        print(f\"{key:25s} {value}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ DEPLOYMENT INSTRUCTIONS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    deployment_code = '''# Load the saved model\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model_data = joblib.load('advanced_traffic_predictor.pkl')\n",
    "model = model_data['model']\n",
    "scaler = model_data['scaler']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# Example prediction function\n",
    "def predict_clearance_time(hour, day_of_week, vehicle_count, is_weekend, \n",
    "                          temperature, visibility, weather_encoded, \n",
    "                          congestion_level_encoded):\n",
    "    \"\"\"Predict traffic clearance time\"\"\"\n",
    "    \n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame([{\n",
    "        'hour': hour,\n",
    "        'day_of_week': day_of_week, \n",
    "        'vehicle_count': vehicle_count,\n",
    "        'is_weekend': is_weekend,\n",
    "        'temperature': temperature,\n",
    "        'visibility': visibility,\n",
    "        'weather_encoded': weather_encoded,\n",
    "        'congestion_level_encoded': congestion_level_encoded\n",
    "    }])\n",
    "    \n",
    "    # Add engineered features (if using advanced model)\n",
    "    if len(feature_names) > 8:\n",
    "        # Add cyclical and other engineered features\n",
    "        input_data['hour_sin'] = np.sin(2 * np.pi * input_data['hour'] / 24)\n",
    "        input_data['hour_cos'] = np.cos(2 * np.pi * input_data['hour'] / 24)\n",
    "        # ... (add other features as needed)\n",
    "    \n",
    "    # Scale and predict\n",
    "    input_scaled = scaler.transform(input_data[feature_names])\n",
    "    prediction = model.predict(input_scaled)[0]\n",
    "    \n",
    "    return round(prediction, 1)\n",
    "\n",
    "# Example usage\n",
    "clearance_time = predict_clearance_time(\n",
    "    hour=8, day_of_week=1, vehicle_count=75, is_weekend=0,\n",
    "    temperature=25, visibility=10, weather_encoded=0, \n",
    "    congestion_level_encoded=2\n",
    ")\n",
    "print(f\"Predicted clearance time: {clearance_time} minutes\")'''\n",
    "    \n",
    "    print(\"üìù Sample deployment code saved in model summary.\")\n",
    "    print(\"\\n‚úÖ Traffic Clearance Predictor is fully operational!\")\n",
    "    print(\"üéâ Ready for real-time traffic management applications!\")\n",
    "    \n",
    "    # Save deployment code to file\n",
    "    with open('deployment_example.py', 'w') as f:\n",
    "        f.write(deployment_code)\n",
    "    print(\"\\nüíæ Deployment example saved as 'deployment_example.py'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Model training was not successful. Please review the errors above.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéä TRAFFIC CLEARANCE PREDICTOR PROJECT COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
