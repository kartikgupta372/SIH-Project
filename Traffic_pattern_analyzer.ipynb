{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644bc62e-ba5d-4f37-af39-730fa752529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class UniversalTrafficAnalyzer:\n",
    "    \"\"\"\n",
    "    Complete Universal Traffic Pattern Analyzer for Jupyter Notebooks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.analysis_results = {}\n",
    "        self.insights = []\n",
    "        self.recommendations = []\n",
    "        self.df = None\n",
    "        self.config = config or self._default_config()\n",
    "        self.column_mapping = {}\n",
    "\n",
    "    def _default_config(self):\n",
    "        return {\n",
    "            'required_columns': {\n",
    "                'vehicle_count': ['vehicle_count', 'vehicles', 'count', 'traffic_volume', 'car_count'],\n",
    "                'hour': ['hour', 'hr', 'time_hour', 'h'],\n",
    "                'day_name': ['day_name', 'day', 'weekday', 'day_of_week_name'],\n",
    "                'congestion_level': ['congestion_level', 'congestion', 'traffic_level', 'jam_level'],\n",
    "                'congestion_duration': ['congestion_duration_minutes', 'duration', 'clearance_time', 'congestion_time']\n",
    "            },\n",
    "            'optional_columns': {\n",
    "                'weather': ['weather', 'weather_condition', 'conditions'],\n",
    "                'temperature': ['temperature', 'temp', 'temp_c', 'temperature_celsius'],\n",
    "                'visibility': ['visibility', 'vis', 'visibility_km'],\n",
    "                'is_weekend': ['is_weekend', 'weekend', 'is_wknd'],\n",
    "                'day_of_week': ['day_of_week', 'dow', 'weekday_num']\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _validate_and_map_columns(self, df):\n",
    "        missing = []\n",
    "        mapping = {}\n",
    "        for std, candidates in self.config['required_columns'].items():\n",
    "            for c in candidates:\n",
    "                if c in df.columns:\n",
    "                    mapping[std] = c\n",
    "                    break\n",
    "            else:\n",
    "                missing.append(std)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "        for std, candidates in self.config['optional_columns'].items():\n",
    "            for c in candidates:\n",
    "                if c in df.columns:\n",
    "                    mapping[std] = c\n",
    "                    break\n",
    "        # build standardized df\n",
    "        std_df = pd.DataFrame({std: df[orig] for std, orig in mapping.items()})\n",
    "        return std_df, mapping\n",
    "\n",
    "    def _categorize_time_period(self, h):\n",
    "        if pd.isna(h): return 'Unknown'\n",
    "        if 6 <= h <= 9: return 'Morning Rush'\n",
    "        if 10 <= h <= 16: return 'Mid-Day'\n",
    "        if 17 <= h <= 20: return 'Evening Rush'\n",
    "        if 21 <= h <= 23: return 'Evening'\n",
    "        return 'Night/Early Morning'\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        for col in self.df.select_dtypes(include=[np.number]).columns:\n",
    "            if self.df[col].isnull().any():\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].median())\n",
    "        if 'hour' in self.df:\n",
    "            self.df['hour'] = pd.to_numeric(self.df['hour'], errors='coerce')\n",
    "        if 'is_weekend' not in self.df and 'day_of_week' in self.df:\n",
    "            self.df['is_weekend'] = (self.df['day_of_week'] >= 5).astype(int)\n",
    "        if 'time_period' not in self.df and 'hour' in self.df:\n",
    "            self.df['time_period'] = self.df['hour'].apply(self._categorize_time_period)\n",
    "\n",
    "    def load_and_prepare_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            df = pd.read_csv(data)\n",
    "        else:\n",
    "            df = data.copy()\n",
    "        std_df, mapping = self._validate_and_map_columns(df)\n",
    "        self.df, self.column_mapping = std_df, mapping\n",
    "        self._preprocess_data()\n",
    "        return self.df\n",
    "\n",
    "    def analyze_peak_hours(self):\n",
    "        stats = self.df.groupby('hour')['vehicle_count'].agg(['mean','max','std']).round(2)\n",
    "        peak = stats['mean'].nlargest(5)\n",
    "        low  = stats['mean'].nsmallest(5)\n",
    "        self.analysis_results['peak_hours'] = {'stats': stats, 'top': peak.index.tolist(), 'low': low.index.tolist()}\n",
    "        return stats\n",
    "\n",
    "    def analyze_daily_patterns(self):\n",
    "        by_day = self.df.groupby('day_name')['vehicle_count'].agg(['mean','max','std']).round(2)\n",
    "        wk = self.df.groupby('is_weekend')['vehicle_count'].mean()\n",
    "        diff = None\n",
    "        if 0 in wk and 1 in wk:\n",
    "            diff = (wk[0]-wk[1])/wk[1]*100\n",
    "        self.analysis_results['daily_patterns'] = {'by_day': by_day, 'weekday_vs_weekend_diff': diff}\n",
    "        return by_day\n",
    "\n",
    "    def analyze_weather_impact(self):\n",
    "        if 'weather' not in self.df: return None\n",
    "        wstats = self.df.groupby('weather')['vehicle_count'].mean().round(2)\n",
    "        self.analysis_results['weather_impact'] = wstats\n",
    "        return wstats\n",
    "\n",
    "    def analyze_congestion_patterns(self):\n",
    "        if 'congestion_level' not in self.df: return None\n",
    "        dist = self.df['congestion_level'].value_counts(normalize=True).mul(100).round(1)\n",
    "        dur = None\n",
    "        if 'congestion_duration' in self.df:\n",
    "            dur = self.df['congestion_duration'].describe().round(1)\n",
    "        self.analysis_results['congestion_patterns'] = {'distribution_%': dist, 'duration_stats': dur}\n",
    "        return dist\n",
    "\n",
    "    def generate_insights(self):\n",
    "        self.insights = []\n",
    "        ph = self.analysis_results.get('peak_hours', {})\n",
    "        if ph: self.insights.append(f\"Peak hour: {ph['top'][0]:02d}:00\")\n",
    "        dp = self.analysis_results.get('daily_patterns', {})\n",
    "        d = dp.get('weekday_vs_weekend_diff')\n",
    "        if d is not None: self.insights.append(f\"Weekday vs weekend diff: {d:.1f}%\")\n",
    "        cp = self.analysis_results.get('congestion_patterns', {}).get('duration_stats')\n",
    "        if cp is not None: self.insights.append(f\"Avg congestion time: {cp['mean']:.1f} min\")\n",
    "\n",
    "    def generate_recommendations(self):\n",
    "        self.recommendations = []\n",
    "        ph = self.analysis_results.get('peak_hours', {}).get('top', [])\n",
    "        if ph: hours = ','.join(f\"{h:02d}:00\" for h in ph[:3]); \n",
    "        self.recommendations.append(f\"Optimize signals at {hours}\")\n",
    "        dp = self.analysis_results.get('daily_patterns',{}).get('weekday_vs_weekend_diff')\n",
    "        if dp and abs(dp)>20: self.recommendations.append(\"Different weekend strategy\")\n",
    "        if 'weather_impact' in self.analysis_results: self.recommendations.append(\"Plan for adverse weather\")\n",
    "\n",
    "    def run_complete_analysis(self, data):\n",
    "        self.load_and_prepare_data(data)\n",
    "        self.analyze_peak_hours()\n",
    "        self.analyze_daily_patterns()\n",
    "        self.analyze_weather_impact()\n",
    "        self.analyze_congestion_patterns()\n",
    "        self.generate_insights()\n",
    "        self.generate_recommendations()\n",
    "        return self.analysis_results\n",
    "\n",
    "# After running the cell above, you can do:\n",
    "\n",
    "# df = pd.read_csv('synthetic_traffic_data.csv')\n",
    "# analyzer = UniversalTrafficAnalyzer()\n",
    "# results = analyzer.run_complete_analysis(df)\n",
    "# print(analyzer.insights)\n",
    "# print(analyzer.recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04498a92-087a-4942-bf8e-47afd84635aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insights: ['Peak hour: 17:00', 'Weekday vs weekend diff: 70.5%', 'Avg congestion time: 27.8 min']\n",
      "Recommendations: ['Optimize signals at 17:00,18:00,08:00', 'Different weekend strategy', 'Plan for adverse weather']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('synthetic_traffic_data.csv')\n",
    "analyzer = UniversalTrafficAnalyzer()\n",
    "results = analyzer.run_complete_analysis(df)\n",
    "print(\"Insights:\", analyzer.insights)\n",
    "print(\"Recommendations:\", analyzer.recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e05bf1-2f0a-4ad0-a43b-533718fbbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584c0f5f-1efd-4f47-a073-ae9571b89b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def load_any_csv_file(file_path):\n",
    "    \"\"\"Load any CSV file and automatically detect traffic-related columns\"\"\"\n",
    "    print(f\"📂 Loading data from: {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"✅ Dataset shape: {df.shape}\")\n",
    "    print(f\"✅ Columns found: {list(df.columns)}\")\n",
    "    print(\"\\n📊 Dataset Info:\")\n",
    "    print(df.info())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84462d00-dced-423d-ad4f-6c66fbd86a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_traffic_columns(df):\n",
    "    \"\"\"Automatically detect important columns in any traffic dataset\"\"\"\n",
    "    column_map = {}\n",
    "    \n",
    "    # Traffic/Vehicle count columns\n",
    "    for col in df.columns:\n",
    "        if any(word in col.lower() for word in ['vehicle', 'count', 'traffic', 'car', 'volume']):\n",
    "            column_map['traffic'] = col\n",
    "            print(f\"✓ Traffic column found: {col}\")\n",
    "            break\n",
    "    \n",
    "    # Hour/Time columns\n",
    "    for col in df.columns:\n",
    "        if any(word in col.lower() for word in ['hour', 'hr', 'time']):\n",
    "            if df[col].dtype in ['int64', 'float64'] and df[col].max() <= 24:\n",
    "                column_map['hour'] = col\n",
    "                print(f\"✓ Hour column found: {col}\")\n",
    "                break\n",
    "    \n",
    "    # Day columns\n",
    "    for col in df.columns:\n",
    "        if any(word in col.lower() for word in ['day_name', 'day', 'weekday']):\n",
    "            column_map['day'] = col\n",
    "            print(f\"✓ Day column found: {col}\")\n",
    "            break\n",
    "    \n",
    "    # Weather columns\n",
    "    for col in df.columns:\n",
    "        if any(word in col.lower() for word in ['weather', 'condition', 'climate']):\n",
    "            column_map['weather'] = col\n",
    "            print(f\"✓ Weather column found: {col}\")\n",
    "            break\n",
    "    \n",
    "    # Congestion columns\n",
    "    for col in df.columns:\n",
    "        if any(word in col.lower() for word in ['congestion', 'level', 'jam']):\n",
    "            column_map['congestion'] = col\n",
    "            print(f\"✓ Congestion column found: {col}\")\n",
    "            break\n",
    "    \n",
    "    return column_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df3572a7-a93b-4732-aa0f-acec21d3cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_traffic_stats(df, traffic_col):\n",
    "    \"\"\"Generate detailed traffic statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DETAILED TRAFFIC STATISTICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    stats = df[traffic_col].describe()\n",
    "    \n",
    "    print(f\"Total Records: {len(df)}\")\n",
    "    print(f\"Average Traffic: {stats['mean']:.1f}\")\n",
    "    print(f\"Peak Traffic: {stats['max']:.0f}\")\n",
    "    print(f\"Minimum Traffic: {stats['min']:.0f}\")\n",
    "    print(f\"Standard Deviation: {stats['std']:.1f}\")\n",
    "    print(f\"Median Traffic: {stats['50%']:.1f}\")\n",
    "    \n",
    "    # Traffic categories\n",
    "    high_traffic = df[df[traffic_col] > stats['75%']]\n",
    "    medium_traffic = df[(df[traffic_col] >= stats['25%']) & (df[traffic_col] <= stats['75%'])]\n",
    "    low_traffic = df[df[traffic_col] < stats['25%']]\n",
    "    \n",
    "    print(f\"\\nTraffic Distribution:\")\n",
    "    print(f\"High Traffic (>75%): {len(high_traffic)} records ({len(high_traffic)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Medium Traffic (25-75%): {len(medium_traffic)} records ({len(medium_traffic)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Low Traffic (<25%): {len(low_traffic)} records ({len(low_traffic)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a779dd-0113-49c1-8885-ba1e374e43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_peak_analysis(df, traffic_col, hour_col):\n",
    "    \"\"\"Advanced analysis of peak hours with rush hour identification\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ADVANCED PEAK HOUR ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    hourly_stats = df.groupby(hour_col)[traffic_col].agg(['mean', 'max', 'std', 'count']).round(1)\n",
    "    \n",
    "    # Identify rush hours (top 25% of traffic)\n",
    "    threshold = hourly_stats['mean'].quantile(0.75)\n",
    "    rush_hours = hourly_stats[hourly_stats['mean'] >= threshold]\n",
    "    \n",
    "    print(\"Peak Hours Analysis:\")\n",
    "    print(f\"Peak Hour: {hourly_stats['mean'].idxmax()}:00 ({hourly_stats['mean'].max():.1f} avg vehicles)\")\n",
    "    print(f\"Quietest Hour: {hourly_stats['mean'].idxmin()}:00 ({hourly_stats['mean'].min():.1f} avg vehicles)\")\n",
    "    \n",
    "    print(f\"\\nRush Hours (Traffic >= {threshold:.1f}):\")\n",
    "    for hour in rush_hours.index:\n",
    "        avg_traffic = rush_hours.loc[hour, 'mean']\n",
    "        max_traffic = rush_hours.loc[hour, 'max']\n",
    "        print(f\"  {hour}:00 - Avg: {avg_traffic:.1f}, Peak: {max_traffic:.1f}\")\n",
    "    \n",
    "    return hourly_stats, rush_hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f4741d-6af3-4404-8246-7633e8849973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_daily_patterns(df, traffic_col, day_col):\n",
    "    \"\"\"Analyze traffic patterns by day of week\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DAILY PATTERN ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    daily_stats = df.groupby(day_col)[traffic_col].agg(['mean', 'max', 'min', 'std']).round(1)\n",
    "    \n",
    "    print(\"Traffic by Day of Week:\")\n",
    "    for day in daily_stats.index:\n",
    "        avg = daily_stats.loc[day, 'mean']\n",
    "        max_val = daily_stats.loc[day, 'max']\n",
    "        min_val = daily_stats.loc[day, 'min']\n",
    "        print(f\"  {day}: Avg {avg:.1f}, Range {min_val:.0f}-{max_val:.0f}\")\n",
    "    \n",
    "    busiest_day = daily_stats['mean'].idxmax()\n",
    "    quietest_day = daily_stats['mean'].idxmin()\n",
    "    \n",
    "    print(f\"\\nBusiest Day: {busiest_day} ({daily_stats.loc[busiest_day, 'mean']:.1f} avg)\")\n",
    "    print(f\"Quietest Day: {quietest_day} ({daily_stats.loc[quietest_day, 'mean']:.1f} avg)\")\n",
    "    \n",
    "    return daily_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d86bfc96-0d50-4d7d-938c-2ac13018741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_weather_impact(df, traffic_col, weather_col):\n",
    "    \"\"\"Analyze how weather conditions affect traffic\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"WEATHER IMPACT ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    weather_stats = df.groupby(weather_col)[traffic_col].agg(['mean', 'count', 'std']).round(1)\n",
    "    \n",
    "    print(\"Traffic by Weather Condition:\")\n",
    "    for weather in weather_stats.index:\n",
    "        avg = weather_stats.loc[weather, 'mean']\n",
    "        count = weather_stats.loc[weather, 'count']\n",
    "        print(f\"  {weather}: {avg:.1f} avg traffic ({count} observations)\")\n",
    "    \n",
    "    best_weather = weather_stats['mean'].idxmax()\n",
    "    worst_weather = weather_stats['mean'].idxmin()\n",
    "    \n",
    "    print(f\"\\nBest Traffic Weather: {best_weather}\")\n",
    "    print(f\"Worst Traffic Weather: {worst_weather}\")\n",
    "    \n",
    "    return weather_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31da4131-00f6-4d4f-a7f9-1fe39b4281bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_traffic_data(csv_file_path):\n",
    "    \"\"\"Main function to run complete traffic analysis on any CSV file\"\"\"\n",
    "    print(\"🚗 STARTING COMPREHENSIVE TRAFFIC ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load data\n",
    "    df = load_any_csv_file(csv_file_path)\n",
    "    \n",
    "    # Detect columns\n",
    "    column_map = detect_traffic_columns(df)\n",
    "    \n",
    "    if 'traffic' not in column_map:\n",
    "        print(\"❌ No traffic data column found!\")\n",
    "        return None\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    traffic_col = column_map['traffic']\n",
    "    stats = detailed_traffic_stats(df, traffic_col)\n",
    "    analysis_results['basic_stats'] = stats\n",
    "    \n",
    "    # Peak hour analysis\n",
    "    if 'hour' in column_map:\n",
    "        hourly_stats, rush_hours = advanced_peak_analysis(df, traffic_col, column_map['hour'])\n",
    "        analysis_results['hourly_stats'] = hourly_stats\n",
    "        analysis_results['rush_hours'] = rush_hours\n",
    "    \n",
    "    # Daily pattern analysis\n",
    "    if 'day' in column_map:\n",
    "        daily_stats = analyze_daily_patterns(df, traffic_col, column_map['day'])\n",
    "        analysis_results['daily_patterns'] = daily_stats\n",
    "    \n",
    "    # Weather analysis\n",
    "    if 'weather' in column_map:\n",
    "        weather_stats = analyze_weather_impact(df, traffic_col, column_map['weather'])\n",
    "        analysis_results['weather_impact'] = weather_stats\n",
    "    \n",
    "    print(\"\\n🎉 ANALYSIS COMPLETED!\")\n",
    "    return analysis_results, column_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c50606d7-c65a-4ef8-817a-2444165ccb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚗 STARTING COMPREHENSIVE TRAFFIC ANALYSIS\n",
      "============================================================\n",
      "📂 Loading data from: synthetic_traffic_data.csv\n",
      "✅ Dataset shape: (168, 12)\n",
      "✅ Columns found: ['date', 'time', 'hour', 'day_of_week', 'day_name', 'vehicle_count', 'congestion_level', 'congestion_duration_minutes', 'is_weekend', 'weather', 'temperature', 'visibility']\n",
      "\n",
      "📊 Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   date                         168 non-null    object \n",
      " 1   time                         168 non-null    object \n",
      " 2   hour                         168 non-null    int64  \n",
      " 3   day_of_week                  168 non-null    int64  \n",
      " 4   day_name                     168 non-null    object \n",
      " 5   vehicle_count                168 non-null    int64  \n",
      " 6   congestion_level             168 non-null    object \n",
      " 7   congestion_duration_minutes  168 non-null    int64  \n",
      " 8   is_weekend                   168 non-null    int64  \n",
      " 9   weather                      168 non-null    object \n",
      " 10  temperature                  168 non-null    float64\n",
      " 11  visibility                   168 non-null    float64\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 15.9+ KB\n",
      "None\n",
      "✓ Traffic column found: vehicle_count\n",
      "✓ Hour column found: hour\n",
      "✓ Day column found: day_of_week\n",
      "✓ Weather column found: weather\n",
      "✓ Congestion column found: congestion_level\n",
      "\n",
      "==================================================\n",
      "DETAILED TRAFFIC STATISTICS\n",
      "==================================================\n",
      "Total Records: 168\n",
      "Average Traffic: 33.5\n",
      "Peak Traffic: 96\n",
      "Minimum Traffic: 0\n",
      "Standard Deviation: 26.4\n",
      "Median Traffic: 33.0\n",
      "\n",
      "Traffic Distribution:\n",
      "High Traffic (>75%): 42 records (25.0%)\n",
      "Medium Traffic (25-75%): 85 records (50.6%)\n",
      "Low Traffic (<25%): 41 records (24.4%)\n",
      "\n",
      "==================================================\n",
      "ADVANCED PEAK HOUR ANALYSIS\n",
      "==================================================\n",
      "Peak Hours Analysis:\n",
      "Peak Hour: 17:00 (74.9 avg vehicles)\n",
      "Quietest Hour: 2:00 (0.0 avg vehicles)\n",
      "\n",
      "Rush Hours (Traffic >= 50.3):\n",
      "  8:00 - Avg: 69.7, Peak: 92.0\n",
      "  13:00 - Avg: 51.7, Peak: 71.0\n",
      "  16:00 - Avg: 63.1, Peak: 72.0\n",
      "  17:00 - Avg: 74.9, Peak: 91.0\n",
      "  18:00 - Avg: 73.7, Peak: 96.0\n",
      "  19:00 - Avg: 51.4, Peak: 70.0\n",
      "\n",
      "==================================================\n",
      "DAILY PATTERN ANALYSIS\n",
      "==================================================\n",
      "Traffic by Day of Week:\n",
      "  0: Avg 40.2, Range 0-92\n",
      "  1: Avg 37.0, Range 0-83\n",
      "  2: Avg 38.0, Range 0-81\n",
      "  3: Avg 36.0, Range 0-86\n",
      "  4: Avg 38.9, Range 0-96\n",
      "  5: Avg 20.9, Range 0-53\n",
      "  6: Avg 23.7, Range 0-56\n",
      "\n",
      "Busiest Day: 0 (40.2 avg)\n",
      "Quietest Day: 5 (20.9 avg)\n",
      "\n",
      "==================================================\n",
      "WEATHER IMPACT ANALYSIS\n",
      "==================================================\n",
      "Traffic by Weather Condition:\n",
      "  Clear: 30.7 avg traffic (51 observations)\n",
      "  Fog: 33.0 avg traffic (34 observations)\n",
      "  Heavy Rain: 39.6 avg traffic (38 observations)\n",
      "  Light Rain: 32.1 avg traffic (45 observations)\n",
      "\n",
      "Best Traffic Weather: Heavy Rain\n",
      "Worst Traffic Weather: Clear\n",
      "\n",
      "🎉 ANALYSIS COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# Run this to analyze your CSV file\n",
    "results, columns = analyze_traffic_data('synthetic_traffic_data.csv')\n",
    "\n",
    "# To analyze your own file, change the filename:\n",
    "# results, columns = analyze_traffic_data('your_traffic_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d58b5-8f11-4a20-abc9-1ae656fcbdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
